{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones para el exámen\n",
    "\n",
    "<strong>Objetivo:</strong> Este examen tiene como objetivo evaluar la capacidad del estudiante para limpiar, explorar, implementar y evaluar modelos de clasificación en un dataset de diabetes. Utilizaremos el «Diabetes Dataset» disponible en Kaggle. Los estudiantes deben demostrar habilidades prácticas en la manipulación de datos, creación de visualizaciones y modelado predictivo.\n",
    "\n",
    "## Contexto y Descripción del Dataset\n",
    "\n",
    "El «[Diabetes Dataset](https://www.kaggle.com/datasets/mathchi/diabetes-data-set)» contiene datos de salud de mujeres de ascendencia indígena Pima que viven cerca de Phoenix, Arizona, EE.UU. La tarea es predecir si un paciente tiene diabetes o no, basándose en ciertas medidas diagnósticas incluidas en el dataset.\n",
    "\n",
    "## Diccionario de Datos:\n",
    "\n",
    "1. Pregnancies: Número de embarazos.\n",
    "2. Glucose: Concentración de glucosa en plasma a las 2 horas en una prueba oral de tolerancia a la glucosa.\n",
    "3. BloodPressure: Presión arterial diastólica (mm Hg).\n",
    "4. SkinThickness: Espesor del pliegue cutáneo del tríceps (mm).\n",
    "5. Insulin: Niveles séricos de insulina a las 2 horas (mu U/ml).\n",
    "6. BMI: Índice de masa corporal (peso en kg / (altura en m)^2).\n",
    "7. DiabetesPedigreeFunction: Función de pedigrí de diabetes.\n",
    "8. Age: Edad (años).\n",
    "9. Outcome: Variable objetivo (1: diabetes, 0: no diabetes).\n",
    "\n",
    "## Requisitos:\n",
    "\n",
    "1. Limpieza de datos:\n",
    "\n",
    "* Identificación y eliminación de valores duplicados: Asegúrate de que no haya registros duplicados que puedan sesgar los resultados del análisis.\n",
    "* Verificación y ajuste de tipos de datos: Verifica que cada columna tenga el tipo de dato correcto (numérico o categórico) y ajusta si es necesario.\n",
    "* Corrección de inconsistencias en valores categóricos: Revisa las categorías de las variables y unifica aquellos valores que puedan estar escritos de diferentes maneras pero que representen lo mismo.\n",
    "* Manejo de valores faltantes adecuadamente: Identifica y maneja los valores faltantes utilizando técnicas apropiadas como la imputación de la mediana, media o moda, según corresponda.\n",
    "\n",
    "2. Exploración de Datos:\n",
    "\n",
    "* Visualizaciones univariadas y multivariadas: Crea histogramas, gráficos de barras, diagramas de dispersión y mapas de calor para entender la distribución y las relaciones entre las variables.\n",
    "* Estadísticas descriptivas: Calcula medidas de tendencia central (media, mediana, moda) y de dispersión (rango, desviación estándar) para cada característica del dataset.\n",
    "\n",
    "3. Implementación de Modelos:\n",
    "\n",
    "* Modelos de Clasificación: Implementa modelos de Random Forest y XGBoost.\n",
    "* Evaluación de Modelos: Evalúa los modelos utilizando métricas como accuracy, precision, recall, F1-score, y ROC-AUC.\n",
    "* Comparación de Rendimiento: Compara los resultados de ambos modelos y discute cuál es el más adecuado para este dataset.\n",
    "\n",
    "## Entrega\n",
    "\n",
    "Los estudiantes deben entregar un archivo .ipynb comentado que incluya:\n",
    "\n",
    "* Proceso completo de limpieza y preprocesamiento de datos.\n",
    "* Visualizaciones y estadísticas descriptivas.\n",
    "* Implementación y evaluación de los modelos de clasificación.\n",
    "* Análisis comparativo del rendimiento de los modelos.\n",
    "\n",
    "Además, el archivo debe subirse a GitHub con un tag de liberación (release tag) que permita identificar la entrega final.\n",
    "\n",
    "## Consideraciones Éticas y Tecnológicas\n",
    "\n",
    "### Consideraciones Éticas:\n",
    "\n",
    "* Transparencia y Reproducibilidad: Asegúrate de que todos los pasos del análisis sean claros y reproducibles. Otros investigadores deben poder seguir tus pasos y llegar a los mismos resultados.\n",
    "* Imparcialidad y Sesgo: Revisa si existen sesgos en los datos que puedan afectar la imparcialidad del modelo. Es importante que los modelos no discriminen injustamente entre diferentes grupos de datos.\n",
    "\n",
    "### Consideraciones Tecnológicas:\n",
    "\n",
    "* Herramientas Utilizadas: Utiliza herramientas estándar como Python, Jupyter Notebook, Pandas, Scikit-learn, Matplotlib y Seaborn.\n",
    "* Escalabilidad: Considera cómo las técnicas aplicadas podrían escalarse para manejar conjuntos de datos más grandes y complejos.\n",
    "* Optimización de Modelos: Aunque este examen no se enfoca en la optimización de hiperparámetros, se debe tener en cuenta para futuras implementaciones y mejorar el rendimiento de los modelos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
